---
title: "The Car Project - Netzer Validation Method"
author: "Ankit Sisodia"
date: "May 8, 2024"
output: html_document
---

## Importing Libraries

```{r}

library(caret)
library(cowplot)
library(dplyr)
library(data.table)
library(fixest)
library(foreign)
library(geometry)
library(ggplot2)
library(ggalt)
library(ggrepel)
library(grid)
library(jpeg)
library(lpdensity)
library(lubridate)
library(magick)
library(MASS)  # for the isoMDS function
library(purrr)
library(randomForest)
library(rddensity)
library(rdrobust)
library(rdlocrand)
library(readstata13)
library(readxl)
library(reshape)
library(sp)
library(sf)
library(SnowballC)
library(stargazer)
library(stringr)
require(tidyr)
library(tm)
library(xgboost)
library(xtable)

rm(list=ls())

```

## Reading Files

```{r}

df <- read.csv("./honestjohn_validation/final_post.csv") %>% distinct()
df <- df [df$Date!="",]
df$date <- mdy_hm(df$Date)
df$Year <- as.numeric(substr(df$date,1,4))

```

## Combining older approach and newer approach

```{r}

print(length(unique(df$Title)))
count_sentences <- function(text) {
  # Split the text by sentence-ending punctuation (., !, ?)
  sentences <- str_split(text, "(?<=[.!?])\\s+", simplify = TRUE)
  # Count the number of sentences
  return(length(sentences))
}
df$SentenceCount <- sapply(df$Message, count_sentences)
print(sum(df$SentenceCount))
df <- unique(df[,c("date","Message","Year")])
# df <- df %>% distinct()

stop_words <- stopwords("en")
# df$title_message <- paste(df$Title,df$Message)
df$title_message <- removeWords(tolower(df$Message), stop_words)
df$title_message <- wordStem(df$title_message, language = "en")
df$title_message <- gsub("[^[:alnum:] ]", "", df$title_message)
df$title_message <- gsub("[[:punct:]]", "", df$title_message)
# df$title_message <- gsub("  ", " ", df$title_message)
df$Message <- NULL
df <- df %>% distinct()

table(df$Year)

```

## BLP Data

```{r}

uk_product_data <- read.csv('exp_uk_product_data.csv', stringsAsFactors=FALSE)

uk_product_data$old_segment_desc <- uk_product_data$Segment_Desc
uk_product_data$segment_name <- ifelse(uk_product_data$Segment_Desc=="A-Segment (Minicars)","A",ifelse(uk_product_data$Segment_Desc=="B-segment (subcompact)","B",ifelse(uk_product_data$Segment_Desc=="C-segment (compact)","C",ifelse(uk_product_data$Segment_Desc=="D-segment (mid-size)","D",ifelse(uk_product_data$Segment_Desc=="E-segment (mid-size luxury sedan)","E",ifelse(uk_product_data$Segment_Desc=="J-segment (SUV)","J",ifelse(uk_product_data$Segment_Desc=="M-segment (MPV)","M","X")))))))
uk_product_data$Segment_Desc <- NULL

uk_product_data <- uk_product_data %>% dplyr::select(clustering_ids,make,model,market_ids,segment_name,car_ids,firm_ids,quantity,shares)

select_image_table <- read.csv('exp_selected_python_image_table.csv',stringsAsFactors = FALSE)

df_data <- merge(uk_product_data,select_image_table,all.x = TRUE)
df_data$Image_name <- NULL

top_makes_for_latex <- df_data %>% filter(segment_name == "B" | segment_name == "D" | segment_name == "J") %>% group_by(make) %>% summarise(total_shares = sum(shares)) %>% slice_max(order_by = total_shares, n = 5) %>% pull(make)
segment_value <- sort(unique(df_data$segment_name))

rm(select_image_table,uk_product_data)

```

## Pre-processing

```{r}

# Function to generate a regex for basic spelling tolerance (e.g., missing one letter)
function_regex <- function(text_string) {
  # Replace spaces in the make/model name with a regex that allows spaces, hyphens, or periods
  # Convert make/model to lowercase for case insensitivity in matching
  escaped_text_string <- tolower(text_string)
  escaped_text_string <- gsub(" ", "[-\\. ]*", escaped_text_string) # Allow zero or more of -, ., or space between words
  escaped_text_string <- gsub("([\\.\\+\\*\\?\\[\\^\\]\\$\\(\\)\\{\\}\\=\\!\\<\\>\\|\\:\\-])", "\\\\\\1", escaped_text_string) # Escape special regex characters

  # Create a regex pattern that ensures the match is bounded by spaces or start/end of the string
  regex <- paste0("(^|\\s)", escaped_text_string, "($|\\s)")
  return(regex)
}

makemodel_mds <- function(market) {
  df_filtered <- df %>% filter(Year==market)
  df_temp <- df_data %>% filter(market_ids==market) %>% dplyr::select(make)
  unique_makemodel <- unique(df_data[,c("clustering_ids","make","model","segment_name")]) %>% filter(model!="500" & model!="GS")

  for(makemodel in unique_makemodel$model) {
  regex <- function_regex(makemodel)  # Generate the regex for each model
  variable_name <- paste0("is_makemodel_", tolower(gsub("[-\\. ]", "_", makemodel)))  # Create a valid variable name
  df_filtered[[variable_name]] <- grepl(regex, df_filtered$title_message, perl = TRUE)  # Use perl = TRUE for complex regex
  }
  
  df_makemodel <- df_filtered[,c(5:ncol(df_filtered))]
  
  prob_makemodel <- colMeans(df_makemodel)
  makemodel <- names(prob_makemodel)  # get column names
  prob_makemodel_joint <- matrix(nrow = ncol(df_makemodel), ncol = ncol(df_makemodel), dimnames = list(makemodel, makemodel))
  
  for (i in 1:ncol(df_makemodel)) {
    for (j in 1:ncol(df_makemodel)) {
      if (i != j) {
      # Probability of both makes appearing in the same message
      prob_makemodel_joint[i, j] <- mean(df_makemodel[, makemodel[i]] & df_makemodel[, makemodel[j]])
    } else {
      # The diagonal should be the probability of the make itself
      prob_makemodel_joint[i, j] <- prob_makemodel[i]
    }
  }
}
  lift_matrix <- matrix(nrow = ncol(df_makemodel), ncol = ncol(df_makemodel), dimnames = list(unique_makemodel$clustering_ids, unique_makemodel$clustering_ids))

  for (i in 1:ncol(df_makemodel)) {
    for (j in 1:ncol(df_makemodel)) {
      lift_matrix[i, j] <- ifelse(prob_makemodel[i] * prob_makemodel[j] == 0, 0, prob_makemodel_joint[i, j] / (prob_makemodel[i] * prob_makemodel[j]))
    }
    }
  
  diag(lift_matrix) <- 0
  makemodel_lift_matrix <- lift_matrix
  
  dist_matrix <- 1 / makemodel_lift_matrix
  dist_matrix[is.infinite(dist_matrix)] <- max(dist_matrix[is.finite(dist_matrix)]) * 10 # Set infinite values to a large number
  dist_matrix <- as.dist(dist_matrix)
  mds_result <- cmdscale(dist_matrix)
  
  mds_coords <- data.frame(f_x = mds_result[, 1], f_y = mds_result[, 2], clustering_ids = unique_makemodel$clustering_ids, make = unique_makemodel$make, model = unique_makemodel$model, segment_name = unique_makemodel$segment_name)
  
  return(mds_coords)
  
}
```

## Plot Function

```{r eval=FALSE}

main_mds_function <- function(mds_data_df, segment_text1, segment_text2, segment_text3, market) {

df_temp <- mds_data_df
df_temp <- df_temp %>% filter(segment_name==segment_text1 | segment_name==segment_text2 | segment_name==segment_text3)
df_temp <- df_temp %>% filter(make %in% top_makes_for_latex)
df <- df_temp
char1 <- "f_x"
char2 <- "f_y"

p <- ggplot(df, aes_string(x=char1, y=char2)) + geom_point(aes(shape=make, color=segment_name), alpha=0.95, size=4) + theme_minimal() + guides(size=FALSE) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"), legend.text = element_text(size=16), axis.title.x = element_text(size=16), axis.title.y = element_text(size=16), axis.text.x = element_text(size=16), axis.text.y = element_text(size=16)) + scale_x_continuous(limits = c(1.2*min(df_temp[[char1]]), 1.2*max(df_temp[[char1]]))) + scale_y_continuous(limits = c(1.2*min(df_temp[[char2]]), 1.2*max(df_temp[[char2]]))) + scale_color_discrete(guide = guide_legend(title = NULL)) + scale_shape_manual(values=1:(nlevels(factor(df$make))),guide = guide_legend(title = NULL)) + theme(legend.position = "bottom", legend.box = "vertical") + xlab("X-AXIS") + ylab("Y-AXIS")  + theme(plot.title = element_text(hjust = 0.5)) + geom_text_repel(aes(label=model), hjust=0, vjust=0, size=6, alpha = 0.9)

for (seg in segment_value) {
  df_seg = df[df$segment_name == seg, ]
  p <- p + geom_encircle(data = df_seg, aes_string(x=char1, y=char2, color = "segment_name"), alpha = 0.3, expand = 0.01)
}

ggsave(paste0("./hj_mds_plot_files/model_plotD_mds_",segment_text1,segment_text2,segment_text3,"-",market,"_",char1,"_",char2,".pdf"), plot=p, dpi = 300, height = 9, width = 9, units = "in")

}

```

## Execution

```{r}

for(market in 2008:2017){
  mds_result <- makemodel_mds(market)
  write.csv(mds_result,paste0("./input_validation_test/xmds_forum_", market,".csv"),row.names = FALSE)
  # main_mds_function(mds_result,"B","D","J",market)
}

```

## Copying Files from Input to Output

```{r}

for(year in 2008:2017){
    structured_data <- read.csv(paste0("./input_validation_test/mds_structured_",year,".csv"),stringsAsFactors = FALSE)
    visual_data <- read.csv(paste0("./input_validation_test/mds_visual_",year,".csv"),stringsAsFactors = FALSE)
    combination_data <- read.csv(paste0("./input_validation_test/mds_combination_",year,".csv"),stringsAsFactors = FALSE)
    forum_data <- read.csv(paste0("./input_validation_test/xmds_forum_",year,".csv"),stringsAsFactors = FALSE)
    
    write.csv(structured_data,paste0("./output_validation_test/xmds_structured_", year,".csv"),row.names = FALSE)
    write.csv(visual_data,paste0("./output_validation_test/xmds_visual_", year,".csv"),row.names = FALSE)
    write.csv(combination_data,paste0("./output_validation_test/xmds_combination_", year,".csv"),row.names = FALSE)
    write.csv(forum_data,paste0("./output_validation_test/xmds_forum_", year,".csv"),row.names = FALSE)
}

```

## Cleaning Up Forum Data

```{r}

for(year in 2008:2017){
    forum_data <- read.csv(paste0("./output_validation_test/xmds_forum_",year,".csv"),stringsAsFactors = FALSE)
    print(dim(forum_data))
    structured_data <- read.csv(paste0("./output_validation_test/xmds_structured_",year,".csv"),stringsAsFactors = FALSE)
    forum_data <- merge(forum_data,structured_data[ , "clustering_ids", drop = FALSE],by = "clustering_ids")
    print(dim(forum_data))
    write.csv(forum_data,paste0("./output_validation_test/xmds_forum_", year,".csv"),row.names = FALSE)
}

for(year in 2008:2017){
    structured_data <- read.csv(paste0("./output_validation_test/xmds_structured_",year,".csv"),stringsAsFactors = FALSE)
    visual_data <- read.csv(paste0("./output_validation_test/xmds_visual_",year,".csv"),stringsAsFactors = FALSE)
    combination_data <- read.csv(paste0("./output_validation_test/xmds_combination_",year,".csv"),stringsAsFactors = FALSE)
    forum_data <- read.csv(paste0("./output_validation_test/xmds_forum_",year,".csv"),stringsAsFactors = FALSE)
    structured_data <- merge(structured_data,forum_data[ , "clustering_ids", drop = FALSE],by = "clustering_ids")
    visual_data <- merge(visual_data,forum_data[ , "clustering_ids", drop = FALSE],by = "clustering_ids")
    combination_data <- merge(combination_data,forum_data[ , "clustering_ids", drop = FALSE],by = "clustering_ids")
    
    print(dim(forum_data))
    print(dim(structured_data))
    print(dim(visual_data))
    print(dim(combination_data))

    structured_data <- structured_data[,c("clustering_ids","s_x","s_y")]
    visual_data <- visual_data[,c("clustering_ids","v_x","v_y")]
    combination_data <- combination_data[,c("clustering_ids","m_x","m_y")]
    forum_data <- forum_data[,c("clustering_ids","f_x","f_y")]
    
    names(structured_data) <- c("clustering_ids","x","y")
    names(visual_data) <- c("clustering_ids","x","y")
    names(combination_data) <- c("clustering_ids","x","y")
    names(forum_data) <- c("clustering_ids","x","y")
    
    write.csv(structured_data,paste0("./output_validation_test/xmds_structured_", year,".csv"),row.names = FALSE)
    write.csv(visual_data,paste0("./output_validation_test/xmds_visual_", year,".csv"),row.names = FALSE)
    write.csv(combination_data,paste0("./output_validation_test/xmds_combination_", year,".csv"),row.names = FALSE)
    write.csv(forum_data,paste0("./output_validation_test/xmds_forum_", year,".csv"),row.names = FALSE)

}

```

## Correlations

```{r}

load_and_dist <- function(method, approach, year) {
  filepath <- paste0("./output_validation_test/x", method, "_", approach, "_", year, ".csv")
  data <- read.csv(filepath, stringsAsFactors = FALSE)
  # data <- data %>% filter(clustering_ids!="2_2" & clustering_ids!="2_4" & clustering_ids!="2_6" & clustering_ids!="3_1" & clustering_ids!="3_4" & clustering_ids!="3_6" & clustering_ids!="14_1" & clustering_ids!="14_2" & clustering_ids!="14_3" & clustering_ids!="14_5" & clustering_ids!="21_1" & clustering_ids!="21_3" & clustering_ids!="21_5" & clustering_ids!="35_2" & clustering_ids!="35_3" & clustering_ids!="37_11" & clustering_ids!="37_2" & clustering_ids!="37_5"  & clustering_ids!="37_6" & clustering_ids!="37_7" & clustering_ids!="37_8"  & clustering_ids!="37_9" & clustering_ids!="55_5" & clustering_ids!="55_9"  & clustering_ids!="68_1" & clustering_ids!="68_2" & clustering_ids!="68_3"  & clustering_ids!="85_1" & clustering_ids!="85_3" & clustering_ids!="85_5"  & clustering_ids!="85_6" & clustering_ids!="85_7" & clustering_ids!="54_1"  & clustering_ids!="54_4" & clustering_ids!="54_6" & clustering_ids!="54_7"  & clustering_ids!="79_1" & clustering_ids!="79_10" & clustering_ids!="79_11" & clustering_ids!="79_12" & clustering_ids!="79_2" & clustering_ids!="79_6" & clustering_ids!="79_8" & clustering_ids!="79_9" & clustering_ids!="84_1" & clustering_ids!="84_2")
  dist_matrix <- as.matrix(dist(data[, c("x", "y")]))
  return(dist_matrix)
}

compare_correlations <- function(start_year=2008, end_year=2017, methods=c("mds")) {
  approaches <- c("structured", "visual", "combination", "forum")
  results <- data.frame(year=integer(), method=character(), 
                        cor_forum_structured=numeric(), 
                        cor_forum_visual=numeric(), 
                        cor_forum_combination=numeric())
  
  for (method in methods) {
    for (year in start_year:end_year) {
      dist_matrices <- list()
      for (approach in approaches) {
        dist_matrices[[approach]] <- load_and_dist(method, approach, year)
      }

      # Extract upper triangles of the matrices as vector
      forum_vec <- as.vector(dist_matrices[["forum"]][upper.tri(dist_matrices[["forum"]])])
      structured_vec <- as.vector(dist_matrices[["structured"]][upper.tri(dist_matrices[["structured"]])])
      visual_vec <- as.vector(dist_matrices[["visual"]][upper.tri(dist_matrices[["visual"]])])
      combination_vec <- as.vector(dist_matrices[["combination"]][upper.tri(dist_matrices[["combination"]])])
      
      # Compute correlations
      cor_forum_structured <- cor(forum_vec, structured_vec)
      cor_forum_visual <- cor(forum_vec, visual_vec)
      cor_forum_combination <- cor(forum_vec, combination_vec)
      
      # Append results to the dataframe
      results <- rbind(results, data.frame(year=year, method=method, 
                            cor_forum_structured=cor_forum_structured, 
                            cor_forum_visual=cor_forum_visual, 
                            cor_forum_combination=cor_forum_combination))
    }
  }
  
  return(results)
}

# Execute the function
correlation_results <- compare_correlations()

mean(abs(correlation_results$cor_forum_structured[correlation_results$method=="mds"]))
mean(abs(correlation_results$cor_forum_visual[correlation_results$method=="mds"]))
mean(abs(correlation_results$cor_forum_combination[correlation_results$method=="mds"]))

mean((correlation_results$cor_forum_structured[correlation_results$method=="mds"]))
mean((correlation_results$cor_forum_visual[correlation_results$method=="mds"]))
mean((correlation_results$cor_forum_combination[correlation_results$method=="mds"]))

```

## RandomForest

```{r}

results_df <- data.frame(random_seed = integer(), year = integer(), str = numeric(), viz = numeric(), comb = numeric(), str_viz = numeric())

seeds <- 1:10

for(seed in seeds){
  set.seed(seed)
for(year in 2008:2017){
  structured_data <- read.csv(paste0("./output_validation_test/xmds_structured_",year,".csv"),stringsAsFactors = FALSE)
  visual_data <- read.csv(paste0("./output_validation_test/xmds_visual_",year,".csv"),stringsAsFactors = FALSE) 
  combination_data <- read.csv(paste0("./output_validation_test/xmds_combination_",year,".csv"),stringsAsFactors = FALSE)
  forum_data <- read.csv(paste0("./output_validation_test/xmds_forum_",year,".csv"),stringsAsFactors = FALSE)

  structured_data <- as.vector(as.matrix(dist(structured_data[, c("x", "y")]))[upper.tri(as.matrix(dist(structured_data[, c("x", "y")])))])
  visual_data <- as.vector(as.matrix(dist(visual_data[, c("x", "y")]))[upper.tri(as.matrix(dist(visual_data[, c("x", "y")])))])
  combination_data <- as.vector(as.matrix(dist(combination_data[, c("x", "y")]))[upper.tri(as.matrix(dist(combination_data[, c("x", "y")])))])
  forum_data <- as.vector(as.matrix(dist(forum_data[, c("x", "y")]))[upper.tri(as.matrix(dist(forum_data[, c("x", "y")])))])
  
  df <- data.frame(structured_data = structured_data, visual_data = visual_data, combination_data = combination_data, forum_data = forum_data)
  
  trainIndex <- createDataPartition(df$forum_data, p = .8, list = FALSE, times = 1)

  trainData <- df[ trainIndex,]
  testData  <- df[-trainIndex,]
  
  model_structured <- randomForest(forum_data ~ structured_data, data=trainData)
  model_visual <- randomForest(forum_data ~ visual_data, data=trainData)
  model_combination <- randomForest(forum_data ~ combination_data, data=trainData)
  model_structured_visual <- randomForest(forum_data ~ structured_data + visual_data, data=trainData)
  
  pred_structured <- predict(model_structured, testData)
  pred_visual <- predict(model_visual, testData)
  pred_combination <- predict(model_combination, testData)
  pred_structured_visual <- predict(model_structured_visual, testData)
  
  mae_structured <- mean(abs(pred_structured - testData$forum_data))
  mae_visual <- mean(abs(pred_visual - testData$forum_data))
  mae_combination <- mean(abs(pred_combination - testData$forum_data))
  mae_structured_visual <- mean(abs(pred_structured_visual - testData$forum_data))

  results_df <- rbind(results_df, data.frame(random_seed = seed, year = year, str = mae_structured, viz = mae_visual, comb = mae_combination, str_viz = mae_structured_visual))


}}

results_df$method <- "mds"

mds_results_df <- results_df

mean(mds_results_df$str)
mean(mds_results_df$viz)
mean(mds_results_df$comb)
mean(mds_results_df$str_viz)

rf_regression_results_df <- mds_results_df

```

## XGBoost

```{r}

results_df <- data.frame(random_seed = integer(), year = integer(), str = numeric(), viz = numeric(), comb = numeric(), str_viz = numeric())

seeds <- 1:10

for(seed in seeds){
  set.seed(seed)
for(year in 2008:2017){
  structured_data <- read.csv(paste0("./output_validation_test/xmds_structured_",year,".csv"),stringsAsFactors = FALSE)
  visual_data <- read.csv(paste0("./output_validation_test/xmds_visual_",year,".csv"),stringsAsFactors = FALSE) 
  combination_data <- read.csv(paste0("./output_validation_test/xmds_combination_",year,".csv"),stringsAsFactors = FALSE)
  forum_data <- read.csv(paste0("./output_validation_test/xmds_forum_",year,".csv"),stringsAsFactors = FALSE)

  structured_data <- as.vector(as.matrix(dist(structured_data[, c("x", "y")]))[upper.tri(as.matrix(dist(structured_data[, c("x", "y")])))])
  visual_data <- as.vector(as.matrix(dist(visual_data[, c("x", "y")]))[upper.tri(as.matrix(dist(visual_data[, c("x", "y")])))])
  combination_data <- as.vector(as.matrix(dist(combination_data[, c("x", "y")]))[upper.tri(as.matrix(dist(combination_data[, c("x", "y")])))])
  forum_data <- as.vector(as.matrix(dist(forum_data[, c("x", "y")]))[upper.tri(as.matrix(dist(forum_data[, c("x", "y")])))])
  
  df <- data.frame(structured_data = structured_data, visual_data = visual_data, combination_data = combination_data, forum_data = forum_data)
  
  trainIndex <- createDataPartition(df$forum_data, p = .8, list = FALSE, times = 1)

  trainData <- df[ trainIndex,]
  testData  <- df[-trainIndex,]
  
  dtrain <- xgb.DMatrix(data = as.matrix(trainData[, -4]), label = trainData$forum_data)
  dtest <- xgb.DMatrix(data = as.matrix(testData[, -4]), label = testData$forum_data)
  
  params <- list(booster = "gbtree", objective = "reg:squarederror", eta = 0.3, max_depth = 6)
  
  model_structured <- xgb.train(params, dtrain, nrounds = 100, watchlist = list(train = dtrain, test = dtest), print_every_n = 10)
  model_visual <- xgb.train(params, xgb.DMatrix(data = as.matrix(trainData[, c("visual_data")]), label = trainData$forum_data), nrounds = 100)
  model_combination <- xgb.train(params, xgb.DMatrix(data = as.matrix(trainData[, c("combination_data")]), label = trainData$forum_data), nrounds = 100)
  model_structured_visual <- xgb.train(params, xgb.DMatrix(data = as.matrix(trainData[, c("structured_data", "visual_data")]), label = trainData$forum_data), nrounds = 100)
  
  pred_structured <- predict(model_structured, dtest)
  pred_visual <- predict(model_visual, as.matrix(testData[, c("visual_data")]))
  pred_combination <- predict(model_combination, as.matrix(testData[, c("combination_data")]))
  pred_structured_visual <- predict(model_structured_visual, as.matrix(testData[, c("structured_data", "visual_data")]))
  
  mae_structured <- mean(abs(pred_structured - testData$forum_data))
  mae_visual <- mean(abs(pred_visual - testData$forum_data))
  mae_combination <- mean(abs(pred_combination - testData$forum_data))
  mae_structured_visual <- mean(abs(pred_structured_visual - testData$forum_data))

results_df <- rbind(results_df, data.frame(random_seed = seed, year = year, str = mae_structured, viz = mae_visual, comb = mae_combination, str_viz = mae_structured_visual))

}}

results_df$method <- "mds"

mds_results_df <- results_df

mean(mds_results_df$str)
mean(mds_results_df$viz)
mean(mds_results_df$comb)
mean(mds_results_df$str_viz)

xg_regression_results_df <- mds_results_df

```

## Combining RF and XGB

```{r}

oos_results_df <- rbind(rf_regression_results_df,xg_regression_results_df)

```

